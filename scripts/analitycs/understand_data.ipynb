{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.mode.chained_assignment = None\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "len(train.filename.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "len(test.filename.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValid(*dirs):\n",
    "    return os.path.isfile(os.path.join(os.getcwd(),*dirs))\n",
    "train['valid_path'] = [isValid('data','imagenes',filename) for filename in train.filename]\n",
    "train.valid_path.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['valid_path'] = [isValid('data','imagenes',filename) for filename in test.filename]\n",
    "test.valid_path.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total = pd.concat([train,test]).reset_index(drop=True)\n",
    "data_total.to_csv(\"etiquetas.csv\", header=True, index_label=False, index = False)\n",
    "sns.histplot(data = data_total, y = \"class\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total['valid_path'] = [isValid(\"data\",\"imagenes\",filename) for filename in data_total.filename]\n",
    "data_total.valid_path.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chequeo de imagenes y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "def make_compress_folders_from_labels(dta:pd.DataFrame,column:str,make_dirs = True,compress_dirs = False):\n",
    "    for label in dta[column].unique():\n",
    "        if  label == None:\n",
    "            label = 'Borrado'\n",
    "        if make_dirs & (not os.path.exists(os.path.join(os.getcwd(), label))):\n",
    "            os.makedirs(os.path.join(os.getcwd(), label))\n",
    "        if compress_dirs:\n",
    "            shutil.make_archive(f\"{label}\", \"zip\", os.path.join(os.getcwd(), f\"{label}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageDraw,ImageFont\n",
    "from tqdm import tqdm\n",
    "def take_labels_out(data:pd.DataFrame,column:str,report_name:str=''):\n",
    "    enriching_list = []\n",
    "    # os.makedirs()\n",
    "    for name in tqdm(data.filename.unique(),total = len(data.filename.unique())):\n",
    "        image_file = Image.open(os.path.join(os.getcwd(),'data','imagenes',name))\n",
    "        image_df = data.loc[data.filename == name]\n",
    "        image_df['Numero de etiquetas diferentes en la imagen'] = image_df.shape[0]\n",
    "        image_df['Numero de clases de etiquetas diferentes en la imagen'] = len(image_df[column].unique())\n",
    "        image_df['duplicamiento de etiqueta en x'] = image_df['xmax'].duplicated(keep=False) & image_df['xmin'].duplicated(keep=False)\n",
    "        image_df['duplicamiento de etiqueta en y'] = image_df['ymax'].duplicated(keep=False) & image_df['ymin'].duplicated(keep=False)\n",
    "        # if 'Mascara_Encabezados' in image_df['class'].unique() : #len(image_df['class'].unique()) < 6:\n",
    "        # image_df['name_with_position'] = ''\n",
    "        image_df['name_of_picture'] = ''\n",
    "        # print(image_df.reset_index())\n",
    "        image_df = image_df.reset_index(drop = True)\n",
    "        for i,row in image_df.iterrows():\n",
    "            # print(i)\n",
    "            if row[column] == None:\n",
    "                row[column] = 'Borrado'\n",
    "            image_df['name_of_picture'][i] = f'{name[:-4]}_{row[column]}_{i}.jpg'\n",
    "            # image_df['name_with_position'][i] = f'{name[:-4]}_{row[\"class\"]}_{(row[\"xmin\"],row[\"ymin\"],row[\"xmax\"],row[\"ymax\"])}_{i}.jpg'\n",
    "            draw_row = ImageDraw.Draw(image_file)\n",
    "            draw_row.rectangle((row['xmin'],row['ymin'],row['xmax'],row['ymax']),outline=(250,0,0))\n",
    "            # font = ImageFont.truetype(\"sans-serif.ttf\", 16)\n",
    "            draw_row.text((row['xmin'],row['ymin']),row[column],(0,0,0))#,font=font)\n",
    "            label_mask = image_file.crop((row['xmin'],row['ymin'],row['xmax'],row['ymax']))\n",
    "            label_mask.save(os.path.join(os.getcwd(),row[column],f'{name[:-4]}_{row[column]}_{i}.jpg'),format=\"JPEG\", quality=90)\n",
    "            # image_file.save(os.path.join(os.getcwd(),'label_data', f'{name[:-4]}_highligted.jpg'), format=\"JPEG\", quality=90)\n",
    "        # print(name)\n",
    "        \n",
    "        # image_file.show()\n",
    "        enriching_list.append(image_df)\n",
    "    data_total_enrich = pd.concat(enriching_list).reset_index(drop = True)   \n",
    "\n",
    "\n",
    "# print(data_total_enrich.mean(numeric_only=True).to_frame())\n",
    "    cols_to_select = data_total_enrich.drop(['xmin','xmax','ymin','ymax'], axis=1).columns\n",
    "    statistic_analisis = data_total_enrich[cols_to_select].describe()\n",
    "\n",
    "    with pd.ExcelWriter(f\"analisis_descriptivo_{report_name}.xlsx\") as writer:\n",
    "        data_total_enrich.to_excel(writer, sheet_name=\"base enriquecida\")  \n",
    "        statistic_analisis.to_excel(writer, sheet_name=\"estadistica descriptiva\") \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendiendo de la revision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_a_cambiar = pd.read_excel(\"Revision imgs.xlsx\")\n",
    "datos_a_cambiar = datos_a_cambiar.rename(columns = {'Carpeta':'Label_Actual','Donde deberia estar':'Label_Deseado'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datos_a_cambiar['folder'] = datos_a_cambiar.Imagen.str.split('_')\n",
    "datos_a_cambiar['folder'] = datos_a_cambiar['folder'].apply(lambda x: f'{x[1]}_{x[2]}')\n",
    "# datos_a_cambiar['revisado'] = False\n",
    "a_revisar = []\n",
    "for i,row in tqdm(datos_a_cambiar.iterrows(),total=datos_a_cambiar.shape[0]):\n",
    "    # print(type(row))\n",
    "    # if not row['revisado']: #row['Label_Deseado'] not in datos_a_cambiar.Label_Actual.unique():\n",
    "    read_path = os.path.join(os.getcwd(),row.folder,f'{row.Imagen}.jpg')\n",
    "    if not os.path.isfile(read_path):\n",
    "        print(row.to_frame().transpose())\n",
    "        a_revisar.append(row.to_frame().transpose())\n",
    "    else:\n",
    "        imagen_tmp = Image.open(read_path)\n",
    "        # print(row['Label_Actual'],row['Label_Deseado'])\n",
    "        if row['Label_Deseado'] == '?':\n",
    "            row['Label_Deseado'] = 'Desconocido'\n",
    "        save_folder = os.path.join(os.getcwd(),f'{row[\"Label_Actual\"]}_covertir_a_{row[\"Label_Deseado\"]}')\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "        imagen_tmp.save(os.path.join(save_folder,f\"{row['Imagen']}.jpg\"),format=\"JPEG\", quality=90)\n",
    "            # datos_a_cambiar['revisado'][i] = True\n",
    "        # time.sleep(5)\n",
    "direcciones_anomalas = pd.concat(a_revisar)\n",
    "direcciones_anomalas.to_csv('archivos_nombres_equivocados.csv',index = False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chequeando por archivos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JUAN PABLO\\Documents\\Anaconda\\envs\\thesis\\lib\\site-packages\\thefuzz\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file(start_path, target_file):\n",
    "    for root, dirs, files in os.walk(start_path):\n",
    "        if target_file in files:\n",
    "            return ['encontrado',{os.path.join(root, target_file)}]\n",
    "        else:\n",
    "            for file_name in files:\n",
    "                partial_ratio = fuzz.partial_ratio(target_file, file_name)\n",
    "                if (partial_ratio >= 97) & (partial_ratio < 100)  :\n",
    "                    return ['coincidencia parcial encontrada', {os.path.join(root, file_name)}]\n",
    "    return ['archivo no encontrado',None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_anomalos = pd.read_csv(\"archivos_nombres_equivocados.csv\")\n",
    "archivos_anomalos['status'] = archivos_anomalos['Imagen'].apply(lambda x: find_file(os.getcwd(),x)[0])\n",
    "archivos_anomalos['location'] = archivos_anomalos['Imagen'].apply(lambda x: find_file(os.getcwd(),x)[1])\n",
    "archivos_anomalos.to_csv('archivos_nombres_equivocados_buscados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_original_etiquetas = pd.read_excel(\"analisis_descriptivo_etiquetas.xlsx\",sheet_name= 'base enriquecida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_original_etiquetas = archivo_original_etiquetas.rename(columns={'class':'old_class'})\n",
    "archivo_original_etiquetas['new_class'] = archivo_original_etiquetas['old_class']\n",
    "# archivo_original_etiquetas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label_base_on_folder_structure(*address,delete = False):\n",
    "    for root,dirs,files in os.walk(os.path.join(os.getcwd(),*address)):#'por_cambiar_etiquetas','Cambio_simple'\n",
    "        for directory in dirs:\n",
    "            for img in os.listdir(os.path.join(root,directory)):\n",
    "                directory_info = directory.split('_')\n",
    "                new_class = directory_info[-1] \n",
    "                if delete:\n",
    "                    new_class = None\n",
    "                img_info = img.split('_')\n",
    "                archivo_original_etiquetas.loc[(archivo_original_etiquetas.filename == f'{img_info[0]}.png') & (archivo_original_etiquetas.name_of_picture == img),'new_class'] = new_class\n",
    "            # print(img.split('_'))\n",
    "        # print(os.listdir(os.path.join(root,directory)),directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_label_base_on_folder_structure('por_cambiar_etiquetas','Cambio_simple')\n",
    "change_label_base_on_folder_structure('por_cambiar_etiquetas','borrar',delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_original_etiquetas.loc[archivo_original_etiquetas.name_of_picture == 'COL000001500_Mascara_Descripciones_1788.jpg']#head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_original_etiquetas.loc[archivo_original_etiquetas.name_of_picture == 'COL000000745_Mascara_Descripciones_1744.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_original_etiquetas = archivo_original_etiquetas.drop(columns=['Unnamed: 0','valid_path','Numero de etiquetas diferentes en la imagen','Numero de clases de etiquetas diferentes en la imagen','duplicamiento de etiqueta en x','duplicamiento de etiqueta en y','name_with_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_original_etiquetas.old_class = archivo_original_etiquetas.old_class.apply(lambda x: x.split('_')[-1])\n",
    "archivo_original_etiquetas.new_class = archivo_original_etiquetas.new_class.apply(lambda x: x.split('_')[-1] if x != None else x)\n",
    "archivo_original_etiquetas.to_csv(\"renombramiento_etiquetas.csv\",index = False)#.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_compress_folders_from_labels(archivo_original_etiquetas,'new_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 985/985 [00:31<00:00, 31.20it/s]\n"
     ]
    }
   ],
   "source": [
    "take_labels_out(archivo_original_etiquetas,'new_class','etiquetas_corregidas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to script understand_data.ipynb --output understanding_labels.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89e57b1b919738f93c5db305682dbe631b3f97c7d2d3419af611126533034c3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
